# Badania symulacyjne

```{=latex}
\fancyhead[LO]{\textbf{\small{Badania symulacyjne}}}
\renewcommand{\headrulewidth}{0.5pt}
```

```{r zaczynam erować, include=F}
library(ggplot2); library(dplyr); library(latex2exp)
library(knitr); library(kableExtra)
opts_chunk$set(fig.pos = "H", warning = F, echo = F, message = F)
```

W celu porównania rozmiarów i mocy testów opisanych w niniejszej pracy, przeprowadza się badania symulacyjne. Wszystkie poszczególne metody będą oznaczone w następujący sposób:

- **test A** -- test asymptotyczny,
- **test B** -- test bootstrapowy,
- **test P** -- test permutacyjny,
- **test BT** -- test oparty o przybliżenie Boxa.

Wszystkie symulacje zostały przeprowadzone przy pomocy środowiska R \cite{Rcoreteam}.

## Opis eksperymentów

```{r parametry i funkcje m}
n = c(25, 35, 50); I = c(26, 101, 251); alpha = 0.05
m_01 <- function(t){ sqrt(6*t/pi)*exp(-6*t)}
m_11 <- function(t){ sqrt(13*t/pi/2)*exp(-13*t/2)}
m_21 <- function(t){ sqrt(11*t/pi/2)*exp(-11*t/2)}
m_31 <- function(t){ sqrt(5)*t^(2/3)*exp(-7*t)}
m_02 <- function(t){ sin(2*pi*t^2)^5 }
m_12 <- function(t){ sin(2*pi*t^2)^3 }
m_22 <- function(t){ sin(2*pi*t^2)^7 }
m_32 <- function(t){ sin(2*pi*t^(9/5))^3 }
```


Zgodnie z eksperymentami przeprowadzonymi w \cite{MCC} oraz \cite{Smaga} dla testów A, B, P i BT, generuje się realizacje procesów losowych $X_i(t)$ postaci
\begin{equation}\label{eqn:sim_model}
X_i(t) = \begin{cases}
m_1(t) + \epsilon_{i1}(t), & t\in[0,1] \\
m_2(t) + \epsilon_{i2}(t), & t\in[1,2]
\end{cases}, \quad i\in 1,2,\dots,n,
\end{equation}
dla funkcji $m_j(t)$ oraz $\epsilon_{ij}(t)$ opisanych poniżej. Rozpatrywany będzie rozmiar próby $n = `r paste(n, collapse = ', ')`$.

Rozpatrywane będą następujące funkcje:

\begin{align*}
m_{0,1}(t) &= \sqrt{\frac{6t}{\pi}}\exp(-6t)I_{[0,1]}(t) &\quad
m_{0,2}(t) &= (\sin(2\pi t^2))^5I_{[0,1]}(t) \\
m_{1,1}(t) &= \sqrt{\frac{13t}{2\pi}}\exp\left(-\frac{13t}{2}\right)I_{[0,1]}(t) &\quad
m_{1,2}(t) &= (\sin(2\pi t^2))^3I_{[0,1]}(t) \\
m_{2,1}(t) &= \sqrt{\frac{11t}{2\pi}}\exp\left(-\frac{11t}{2}\right)I_{[0,1]}(t) &\quad
m_{2,2}(t) &= (\sin(2\pi t^2))^7I_{[0,1]}(t) \\
m_{3,1}(t) &= \sqrt{5}t^{\frac{2}{3}}\exp(-7t)I_{[0,1]}(t) &\quad
m_{3,2}(t) &= (\sin(2\pi t^{\frac{9}{5}}))^3I_{[0,1]}(t)
\end{align*}

Wykresy powyższych funkcji są przedstawione na Rysunku \@ref(fig:wykresy).

```{r wykresy, fig.cap="Wykresy funkcji $m_{i,j}(t), t\\in[0,1]$, wykorzystanych do przeprowadzenia symulacji", fig.height=3}
#wykresy chikwadratowe
ggplot(data.frame(x = 0:1), aes(x)) +
  theme_minimal() + theme(legend.position = "bottom") +
  geom_function(fun = m_01, aes(color = 'a')) +
  geom_function(fun = m_11, aes(color = 'b')) +
  geom_function(fun = m_21, aes(color = 'c')) +
  geom_function(fun = m_31, aes(color = 'd')) +
  xlab("t") + ylab("") + 
  scale_color_manual(name = "",
                     values = c('a'='black', 'b'='red', 'c'='green', 'd'='blue'),
                     labels = c(TeX("$m_{0,1}(t)$"),
                                TeX("$m_{1,1}(t)$"),
                                TeX("$m_{2,1}(t)$"),
                                TeX("$m_{3,1}(t)$"))) -> plot1
#wykresy sinusowe
ggplot(data.frame(x = 0:1), aes(x)) +
  theme_minimal() + theme(legend.position = "bottom") +
  geom_function(fun = m_02, aes(color = 'a')) +
  geom_function(fun = m_12, aes(color = 'b')) +
  geom_function(fun = m_22, aes(color = 'c')) +
  geom_function(fun = m_32, aes(color = 'd')) +
  xlab("t") + ylab("") + 
  scale_color_manual(name = "",
                     values = c('a'='black', 'b'='red', 'c'='green', 'd'='blue'),
                     labels = c(TeX("$m_{0,2}(t)$"),
                                TeX("$m_{1,2}(t)$"),
                                TeX("$m_{2,2}(t)$"),
                                TeX("$m_{3,2}(t)$"))) -> plot2
#multiwykres
gridExtra::grid.arrange(plot1, plot2, nrow = 1)
```

Skonstruowanych zostanie 8 różnych modeli spełniających równanie modelu \eqref{eqn:sim_model}:

- dla **modeli M0-M3** przyjmuje się $m_1 = m_{0,1}, \quad m_2 = m_{j,1}, j = 0,1,2,3$
- dla **modeli M4-M7** przyjmuje się $m_1 = m_{0,2}, \quad m_2 = m_{j,2}, j = 0,1,2,3$

Warto zauważyć, że dla modeli M0 oraz M4 hipoteza zerowa jest prawdziwa.

Występujące w równaniu \eqref{eqn:sim_model} procesy $\epsilon_{i1}, \epsilon_{i2}$ konstruuje się na bazie procesów gaussowskich. Rozpatrywane będą trzy rodzaje procesów losowych, dalej nazywanych *błędami*:

```{r funkcje epsilon, echo = T}
#nie jestem pewien do końca, jak definiować te funkcje losowe w R
eps_1_n <- function(xi){ xi*rnorm() }
eps_2_n <- function(xi, rho){ rho*eps_1_norm(xi) + xi*sqrt(1-rho^2)*rnorm() }
eps_1_l <- function(xi){ exp(eps_1_n(xi)) }
eps_2_l <- function(xi){ exp(eps_2_n(xi)) }
rho <- c(0, 0.25, 0.5)

# kod dla trzech przypadków
time = seq(0, 1, by = 0.001)
n <- 25
g <- 1 / 4

# normal
yy <- matrix(rep(0, n * 2002), nrow = n)
M0 <- (sin(2 * pi * time^2))^5
for(i in 1:n) {
  X <- cumsum(rnorm(1001, mean = 0, sd = sqrt(1 / 1001)))
  Z <- X - time * X[1001]
  X1 <- cumsum(rnorm(1001, mean = 0, sd = sqrt(1 / 1001)))
  Z1 <- X1 - time * X1[1001]
  e1 <- (1 / 2) * Z
  yy[i, 1:1001] <- M0 + e1
  yy[i, 1002:2002] <- M0 + g * e1 + (1 / 2) * sqrt(1 - g^2) * Z1
}
# 26 punktów czaowych
yy <- yy[, c(seq(1, 1001, by = 40), seq(1002, 2002, by = 40))]
matplot(t(yy), type = "l")
# 101 punktów czaowych
# yy <- yy[, c(seq(1, 1001, by = 4), seq(1002, 2002, by = 4))]
# matplot(t(yy), type = "l")

# lognormal
yy <- matrix(rep(0, n * 2002), nrow = n)
M0 <- (sin(2 * pi * time^2))^5
for(i in 1:n) {
  X <- cumsum(rnorm(1001, mean = 0, sd = sqrt(1 / 1001)))
  Z <- X - time * X[1001]
  X1 <- cumsum(rnorm(1001, mean = 0, sd = sqrt(1 / 1001)))
  Z1 <- X1 - time * X1[1001]
  e1 <- (1 / 2) * Z
  ee1 <- exp(e1)
  ee2 <- exp(g * e1 + (1 / 2) * sqrt(1 - g^2)*Z1)
  yy[i,1:1001] <- M0 + ee1 - mean(ee1)
  yy[i,1002:2002] <- M0 + ee2 - mean(ee2)
}
# 26 punktów czaowych
yy <- yy[, c(seq(1, 1001, by = 40), seq(1002, 2002, by = 40))]
matplot(t(yy), type = "l")

# mixed
yy <- matrix(rep(0, n * 2002), nrow = n)
M0 <- (sin(2 * pi * time^2))^5
for(i in 1:n) {
  X <- cumsum(rnorm(1001, mean = 0, sd = sqrt(1 / 1001)))
  Z <- X - time * X[1001]
  X1 <- cumsum(rnorm(1001, mean = 0, sd = sqrt(1 / 1001)))
  Z1 <- X1 - time * X1[1001]
  e1 <- (1 / 2) * Z
  yy[i, 1:1001] <- M0 + e1
  e2c <- exp(g * e1 + (1 / 2) * sqrt(1 - g^2)*Z1)
  yy[i,1002:2002] <- M0 + e2c - mean(e2c)
}
# 26 punktów czaowych
yy <- yy[, c(seq(1, 1001, by = 40), seq(1002, 2002, by = 40))]
matplot(t(yy), type = "l")
```

- **normalny**: $\epsilon_{i1}(t) := \xi B_{i1}(t), \quad \epsilon_{i2}(t) := \rho\epsilon_{i1}(t) + \xi\sqrt{1-\rho^2}B_{i2}(t)$ ($\rho = `r paste(rho, collapse = ', ')`$),
- **lognormalny**: $\epsilon_{ij}(t) := \exp(\epsilon_{ij}(t)), j=1,2$,
- **mieszany**: $\epsilon_{i1}(t) := \epsilon_{i1}(t), \quad \epsilon_{i2}(t) := \exp(\epsilon_{i2}(t))$.

\AAA{chyba nie obejdę tego pisania o mostach Browna}

Jako że obliczenie wartości danych funkcji jest możliwe jedynie w dyskretnej liczbie punktów, na potrzeby symulacji wartości procesów $X_i(t), X_i(t+1)$ wygenerowane zostały dla $I$ punktów ($I=`r paste(I, collapse = ', ')`$): $t_r\in[0,1], r\in 1,2,\dots,I$, dzielących odcinek $[0,1]$ na $I$ równych fragmentów.

Dokonano obliczeń **rozmiarów** i **mocy** empirycznych rozważanych testów na poziomie istotności $\alpha = `r alpha*100`\%$, na podstawie 1000 replikacji. Wyniki przedstawiono w tabelach zaprezentowanych w dalszej części pracy.

\begin{defi}
Niech \textcolor{blue}{$\mathbf{X}$ będzie próbą}, a $B$ obszarem krytycznym testu statystycznego.\\
\textbf{Rozmiarem} testu statystycznego jest prawdopodobieństwo nieprawidłowego odrzucenia hipotezy zerowej, tj. błędu I rodzaju:
\[
\doubleP_0(\mathbf{X}\in B).
\]
\textbf{Mocą} testu statystycznego jest prawdopodobieństwo poprawnego odrzucenia hipotezy zerowej, tj. zdarzenia przeciwnego do błędu II rodzaju:
\[
\doubleP_1(\mathbf{X}\in B).
\]
\end{defi}
\AAA{czy są gdzieś w bibliografii bardziej oficjalne definicje rozmiaru i mocy? bo nie znalazłem} \textcolor{blue}{moc jest na pewno zdefiniowana w książce Krzyśko M., Statystyka matematyczna. Wydawnictwo Naukowe UAM, ale rozmiar to niekoniecznie, ale to nie jest takie ważne. Można podać tę pozycję, albo wcale.}

## Kontrola błędu pierwszego rodzaju

\AAA{Nie rozumiem struktury tego rozdziału -- czy to, co miało być powiedziane w 1. sekcji, już zostało powiedziane i w 2. będą tabele i wnioski nt. rozmiaru, a w 3. nt. mocy? Czy tabele dać w 1. i w 2./3. będą wnioski?} \textcolor{blue}{tutaj powinny być wyniki (tabelka) dla rozmiaru i ich opis, a kolejnym podrozdziale to samo tylko dla mocy}

```{r funkcje testujące, echo = T}
calc_Cn <- function(x){
  n = nrow(x); p = ncol(x)
  Cn = n*sum((colMeans(x[, 1:(p/2)]) - colMeans(x[, (p/2+1):p]))^2)
  return(Cn)
}
A.test <- function(x){ #asymptotyczny
  #nie wiem, jak to zbudować
}
B.test <- function(x){ #bootstrapowy
  n = nrow(x); p = ncol(x); B = 1000
  C0 = calc_Cn(x)
  #wybranie próby bootstrapowej
  xboot = list()# lista xboot będzie je zawierać
  #obliczanie Cn do bootstrapów
  C = vector("double", B)
  for(i in 1:B){
    C[i] = calc_Cn(xboot[[i]])
  }
  #p-wartość
  p.value = sum(C > C0)/B
  return(p.value)
}
P.test <- function(x){ #permutacyjny
  n = nrow(x); p = ncol(x); B = 1000
  C0 = calc_Cn(x)
  #wybranie próby bootstrapowej
  xperm = list()# lista xperm będzie je zawierać
  #obliczanie Cn do bootstrapów
  C = vector("double", B)
  for(i in 1:B){
    C[i] = calc_Cn(xperm[[i]])
  }
  #p-wartość
  p.value = sum(C > C0)/B
  return(p.value)
}
BT.test <- function(x){ #box-type
  n = nrow(x); p = ncol(x); CC = var(x)
  Cn = calc_Cn(x)
  KK = CC[1:(p/2), 1:(p/2)] - CC[1:(p/2), (p/2+1):p] -
CC[(p/2+1):p, 1:(p/2)] + CC[(p/2+1):p, (p/2+1):p]
  A = sum(diag(KK)); B = sum(diag(KK%*%KK)); beta = B/A; d = (A^2)/B
  p.value = 1 - pchisq(Cn/beta, d)
  return(c(Cn/(p/2), p.value))
}
```

```{r symulacja}
set.seed(1)
```



## Moc testu